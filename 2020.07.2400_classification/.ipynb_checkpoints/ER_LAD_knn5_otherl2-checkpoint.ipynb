{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Reflection + Least Absolute Deviations\n",
    "\n",
    "In the following, we demonstrate how to apply Least Absolute Deviations (LAD) for classification task such as medical diagnosis.\n",
    "\n",
    "We import the necessary packages to the Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,\\\n",
    "recall_score,roc_curve,auc\n",
    "\n",
    "import expectation_reflection as ER\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from function import split_train_test,make_data_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the processed data are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1paradox' '2peptide' '3stigma' '4nki' '5mental' '6smoking' '7anemia'\n",
      " '8language' '9coag' '10tazamia' '11hepato' '12heat' '13ef' '14cervix'\n",
      " '15heart' '16liver' '17nwosu' '18school' '19ibs' '21survival'\n",
      " '29parkinson' '30paradox2' '31renal' '33svr' '35pcos' '36probiotic'\n",
      " '101kidney' '102breast_cancer' '103diabetes_niddk'\n",
      " '104diabetic_retinopathy']\n"
     ]
    }
   ],
   "source": [
    "data_list = np.loadtxt('data_list_30sets.txt',dtype='str')\n",
    "#data_list = ['29parkinson','30paradox2','31renal','32patientcare','33svr','34newt','35pcos']\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_id):    \n",
    "    data_name = data_list[data_id]\n",
    "    print('data_name:',data_name)\n",
    "    Xy = np.loadtxt('../classification_data/%s/data_processed_knn5.dat'%data_name) \n",
    "    X = Xy[:,:-1]\n",
    "    #y = Xy[:,-1]\n",
    "    # 2020.07.15: convert y from {-1,+1} to {0,1}:\n",
    "    y = (Xy[:,-1]+1)/2. \n",
    "\n",
    "    #print(np.unique(y,return_counts=True))\n",
    "\n",
    "    X,y = make_data_balance(X,y)\n",
    "\n",
    "    print(np.unique(y,return_counts=True))\n",
    "\n",
    "    X, y = shuffle(X, y, random_state=1)\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state = 1)\n",
    "    \n",
    "    sc = MinMaxScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(X_train,X_test,y_train,y_test):\n",
    "\n",
    "    n = X_train.shape[1]\n",
    "\n",
    "    #l2 = [0.0001,0.001,0.01,0.1,1.,10.,100.]\n",
    "    l2 = [0.00001,0.0005,0.0001,0.005,0.001,0.005,0.1,1.,5.]\n",
    "    nl2 = len(l2)\n",
    "\n",
    "    # cross validation \n",
    "    kf = 4   \n",
    "    kfold = KFold(n_splits=kf,shuffle=False)\n",
    "\n",
    "    h01 = np.zeros(kf)\n",
    "    w1 = np.zeros((kf,n))\n",
    "    cost1 = np.zeros(kf)\n",
    "\n",
    "    h0 = np.zeros(nl2)\n",
    "    w = np.zeros((nl2,n))\n",
    "    cost = np.zeros(nl2)            \n",
    "    for il2 in range(len(l2)):            \n",
    "        for i,(train_index,val_index) in enumerate(kfold.split(y_train)):\n",
    "            X_train1, X_val = X_train[train_index], X_train[val_index]\n",
    "            y_train1, y_val = y_train[train_index], y_train[val_index]\n",
    "            #h01[i],w1[i,:] = ER.fit(X_train1,y_train1,niter_max=100,l2=l2[il2])\n",
    "            h01[i],w1[i,:] = ER.fit_LAD(X_train1,y_train1,niter_max=100,l2=l2[il2])\n",
    "\n",
    "            y_val_pred,p_val_pred = ER.predict(X_val,h01[i],w1[i])\n",
    "            cost1[i] = ((p_val_pred - y_val)**2).mean()\n",
    "\n",
    "        h0[il2] = h01.mean(axis=0)\n",
    "        w[il2,:] = w1.mean(axis=0)\n",
    "        cost[il2] = cost1.mean()\n",
    "\n",
    "    # optimal value of l2:\n",
    "    il2_opt = np.argmin(cost)\n",
    "    print('optimal l2:',l2[il2_opt])\n",
    "\n",
    "    # performance:\n",
    "    y_test_pred,p_test_pred = ER.predict(X_test,h0[il2_opt],w[il2_opt,:])\n",
    "\n",
    "    fp,tp,thresholds = roc_curve(y_test, p_test_pred, drop_intermediate=False)\n",
    "\n",
    "    roc_auc = auc(fp,tp)\n",
    "    #print('AUC:', roc_auc)\n",
    "\n",
    "    acc = accuracy_score(y_test,y_test_pred)\n",
    "    #print('Accuracy:', acc)\n",
    "\n",
    "    precision = precision_score(y_test,y_test_pred)\n",
    "    #print('Precision:',precision)\n",
    "\n",
    "    recall = recall_score(y_test,y_test_pred)\n",
    "    #print('Recall:',recall)\n",
    "\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    return acc,roc_auc,precision,recall,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_name: 1paradox\n",
      "(array([0., 1.]), array([60, 60]))\n",
      "optimal l2: 0.0001\n",
      "0 0.85 0.8772032902467685 0.7692307692307693 0.8695652173913043 0.8163265306122449\n",
      "data_name: 2peptide\n",
      "(array([0., 1.]), array([23, 23]))\n",
      "optimal l2: 0.005\n",
      "1 1.0 1.0 1.0 1.0 1.0\n",
      "data_name: 3stigma\n",
      "(array([0., 1.]), array([2725, 2725]))\n",
      "optimal l2: 0.001\n",
      "2 0.9919266055045871 0.9933476852659957 1.0 0.983679525222552 0.9917726252804786\n",
      "data_name: 4nki\n",
      "(array([0., 1.]), array([77, 77]))\n",
      "optimal l2: 1.0\n",
      "3 0.7792207792207793 0.8216216216216214 0.7948717948717948 0.775 0.7848101265822786\n",
      "data_name: 5mental\n",
      "(array([0., 1.]), array([147, 147]))\n",
      "optimal l2: 5.0\n",
      "4 0.6666666666666666 0.7129355077835433 0.684931506849315 0.6578947368421053 0.6711409395973155\n",
      "data_name: 6smoking\n",
      "(array([0., 1.]), array([722, 722]))\n",
      "optimal l2: 1e-05\n",
      "5 1.0 0.9999999999999999 1.0 1.0 1.0\n",
      "data_name: 7anemia\n",
      "(array([0., 1.]), array([43, 43]))\n",
      "optimal l2: 0.001\n",
      "6 0.7209302325581395 0.8114035087719298 0.7692307692307693 0.5263157894736842 0.625\n",
      "data_name: 8language\n",
      "(array([0., 1.]), array([267, 267]))\n",
      "optimal l2: 0.005\n",
      "7 0.7752808988764045 0.8472643523199641 0.7633587786259542 0.7751937984496124 0.7692307692307694\n",
      "data_name: 9coag\n",
      "(array([0., 1.]), array([504, 504]))\n",
      "optimal l2: 0.1\n",
      "8 0.6309523809523809 0.6943608963356062 0.6164874551971327 0.6852589641434262 0.649056603773585\n",
      "data_name: 10tazamia\n",
      "(array([0., 1.]), array([124, 124]))\n",
      "optimal l2: 0.1\n",
      "9 0.75 0.8351977107180021 0.8444444444444444 0.6129032258064516 0.7102803738317757\n",
      "data_name: 11hepato\n",
      "(array([0., 1.]), array([63, 63]))\n",
      "optimal l2: 0.0005\n",
      "10 0.6031746031746031 0.6686868686868687 0.6 0.5 0.5454545454545454\n",
      "data_name: 12heat\n",
      "(array([0., 1.]), array([83, 83]))\n",
      "optimal l2: 1.0\n",
      "11 0.6746987951807228 0.7391304347826088 0.6190476190476191 0.7027027027027027 0.6582278481012659\n",
      "data_name: 13ef\n",
      "(array([0., 1.]), array([93, 93]))\n",
      "optimal l2: 1e-05\n",
      "12 1.0 1.0 1.0 1.0 1.0\n",
      "data_name: 14cervix\n",
      "(array([0., 1.]), array([24, 24]))\n",
      "optimal l2: 1e-05\n",
      "13 0.9166666666666666 1.0 1.0 0.8181818181818182 0.9\n",
      "data_name: 15heart\n",
      "(array([0., 1.]), array([138, 138]))\n",
      "optimal l2: 0.1\n",
      "14 0.8695652173913043 0.940546218487395 0.8513513513513513 0.9 0.875\n",
      "data_name: 16liver\n",
      "(array([0., 1.]), array([167, 167]))\n",
      "optimal l2: 0.0001\n",
      "15 0.7065868263473054 0.7735632183908047 0.7261904761904762 0.7011494252873564 0.7134502923976608\n",
      "data_name: 17nwosu\n",
      "(array([0., 1.]), array([59, 59]))\n",
      "optimal l2: 1e-05\n",
      "16 1.0 1.0 1.0 1.0 1.0\n",
      "data_name: 18school\n",
      "(array([0., 1.]), array([68, 68]))\n"
     ]
    }
   ],
   "source": [
    "n_data = len(data_list)\n",
    "roc_auc = np.zeros(n_data)   ; acc = np.zeros(n_data)\n",
    "precision = np.zeros(n_data) ; recall = np.zeros(n_data)\n",
    "f1_score = np.zeros(n_data)\n",
    "for data_id in range(n_data):\n",
    "    X_train,X_test,y_train,y_test = read_data(data_id)\n",
    "    acc[data_id],roc_auc[data_id],precision[data_id],recall[data_id],f1_score[data_id] =\\\n",
    "            measure_performance(X_train,X_test,y_train,y_test)\n",
    "    print(data_id,acc[data_id],roc_auc[data_id],precision[data_id],recall[data_id],f1_score[data_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('acc_mean:',acc.mean())\n",
    "print('roc_mean:',roc_auc.mean())\n",
    "print('precision:',precision.mean())\n",
    "print('recall:',recall.mean())\n",
    "print('f1_score:',f1_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('result_knn5_ER_LAD_otherl2.dat',(roc_auc,acc,precision,recall,f1_score),fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
