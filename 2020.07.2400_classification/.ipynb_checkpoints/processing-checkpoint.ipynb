{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values and convert binary to +-1, category to one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.Gen</th>\n",
       "      <th>2.Sym</th>\n",
       "      <th>3.Alc</th>\n",
       "      <th>4.HepB</th>\n",
       "      <th>7.HepC</th>\n",
       "      <th>8.Cir</th>\n",
       "      <th>11.Dia</th>\n",
       "      <th>12.Obe</th>\n",
       "      <th>14.Art</th>\n",
       "      <th>15.CRen</th>\n",
       "      <th>...</th>\n",
       "      <th>36.Alb</th>\n",
       "      <th>37.Bil</th>\n",
       "      <th>38.Ala</th>\n",
       "      <th>39.Aspa</th>\n",
       "      <th>40.Gam</th>\n",
       "      <th>41.Alk</th>\n",
       "      <th>42.Prot</th>\n",
       "      <th>43.Crea</th>\n",
       "      <th>44.NNod</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>41</td>\n",
       "      <td>183.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>68</td>\n",
       "      <td>202.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64</td>\n",
       "      <td>94.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>147.0</td>\n",
       "      <td>306</td>\n",
       "      <td>173.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>91.0</td>\n",
       "      <td>122</td>\n",
       "      <td>242.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1.Gen  2.Sym  3.Alc  4.HepB  7.HepC  8.Cir  11.Dia  12.Obe  14.Art  \\\n",
       "0      1    0.0      1     0.0     0.0      1     1.0     NaN     0.0   \n",
       "1      1    0.0      1     1.0     0.0      1     0.0     0.0     1.0   \n",
       "2      1    1.0      1     0.0     0.0      1     1.0     0.0     1.0   \n",
       "3      1    1.0      1     1.0     0.0      1     0.0     0.0     1.0   \n",
       "4      1    0.0      1     0.0     0.0      1     0.0     1.0     0.0   \n",
       "\n",
       "   15.CRen  ...  36.Alb  37.Bil  38.Ala  39.Aspa  40.Gam  41.Alk  42.Prot  \\\n",
       "0      0.0  ...     3.4     2.1    34.0       41   183.0   150.0      7.1   \n",
       "1      1.0  ...     3.3     0.4    58.0       68   202.0   109.0      7.0   \n",
       "2      0.0  ...     3.7     0.4    16.0       64    94.0   174.0      8.1   \n",
       "3      1.0  ...     4.1     0.7   147.0      306   173.0   109.0      6.9   \n",
       "4      0.0  ...     3.4     3.5    91.0      122   242.0   396.0      5.6   \n",
       "\n",
       "   43.Crea  44.NNod  Class  \n",
       "0     0.70      1.0      1  \n",
       "1     2.10      5.0      1  \n",
       "2     1.11      2.0      0  \n",
       "3     1.80      1.0      1  \n",
       "4     0.90      1.0      0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_cleaned.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162 entries, 0 to 161\n",
      "Data columns (total 36 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   1.Gen         162 non-null    int64  \n",
      " 1   2.Sym         145 non-null    float64\n",
      " 2   3.Alc         162 non-null    int64  \n",
      " 3   4.HepB        145 non-null    float64\n",
      " 4   7.HepC        153 non-null    float64\n",
      " 5   8.Cir         162 non-null    int64  \n",
      " 6   11.Dia        159 non-null    float64\n",
      " 7   12.Obe        152 non-null    float64\n",
      " 8   14.Art        159 non-null    float64\n",
      " 9   15.CRen       160 non-null    float64\n",
      " 10  16.HIV        148 non-null    float64\n",
      " 11  19.Spl        147 non-null    float64\n",
      " 12  20.PHyp       151 non-null    float64\n",
      " 13  21.Thr        160 non-null    float64\n",
      " 14  22.LMet       159 non-null    float64\n",
      " 15  23.Rad        161 non-null    float64\n",
      " 16  24.Agedia     162 non-null    int64  \n",
      " 17  27.Sta        162 non-null    int64  \n",
      " 18  28.Encdeg     161 non-null    float64\n",
      " 19  29.Ascdeg     160 non-null    float64\n",
      " 20  30.IntNorRat  161 non-null    float64\n",
      " 21  31.Alp        156 non-null    float64\n",
      " 22  32.Hae        162 non-null    float64\n",
      " 23  33.MCorVol    162 non-null    float64\n",
      " 24  34.Leu        162 non-null    float64\n",
      " 25  35.Plat       162 non-null    float64\n",
      " 26  36.Alb        159 non-null    float64\n",
      " 27  37.Bil        160 non-null    float64\n",
      " 28  38.Ala        161 non-null    float64\n",
      " 29  39.Aspa       162 non-null    int64  \n",
      " 30  40.Gam        162 non-null    float64\n",
      " 31  41.Alk        162 non-null    float64\n",
      " 32  42.Prot       154 non-null    float64\n",
      " 33  43.Crea       158 non-null    float64\n",
      " 34  44.NNod       161 non-null    float64\n",
      " 35  Class         162 non-null    int64  \n",
      "dtypes: float64(29), int64(7)\n",
      "memory usage: 45.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n"
     ]
    }
   ],
   "source": [
    "## separte features and target:\n",
    "target = df.columns[-1]\n",
    "print(target)\n",
    "\n",
    "dfx = df.drop(target,axis=1)\n",
    "dfy = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniques of each variable:\n",
      "[  2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2  50   5\n",
      "   3   3  87 131  71 128 105 131  41  62  93 107 139 124  46  84   6]\n"
     ]
    }
   ],
   "source": [
    "# number of uniques of each column (excluding NaN)\n",
    "nu = np.array([len(pd.unique(dfx[col].dropna())) for col in dfx.columns])\n",
    "print('number of uniques of each variable:')\n",
    "print(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def define_variable_type(df,nu):\n",
    "    i_binary = [] ; i_category = [] ; i_continuous = []\n",
    "    for i in range(len(nu)):\n",
    "        if nu[i] == 2: # binary \n",
    "            i_binary.append(i)\n",
    "        elif nu[i] < 5: # !!!! NOTE: this is not always correct, depending on data\n",
    "            i_category.append(i)\n",
    "        else:\n",
    "            i_continuous.append(i)\n",
    "\n",
    "    print('i_binary:',i_binary)\n",
    "    print('i_category:',i_category)   \n",
    "    #i_binary, i_category, i_continuous\n",
    "    \n",
    "    variable_type  = np.ones(len(nu))  # binary\n",
    "    variable_type[i_category] = 2   # categorical\n",
    "    variable_type[i_continuous] = 3 # continuous\n",
    "\n",
    "    return variable_type #,i_binary,i_category,i_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_binary: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "i_category: [18, 19]\n",
      "variable type: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 3. 3. 2. 2. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "variable_type = define_variable_type(dfx,nu)\n",
    "print('variable type:',variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing values with column mean and column mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_mean(df,variable_type):\n",
    "    # impute binary and categorical variables by the most frequency (in each column)\n",
    "    # continuous variable by median\n",
    "    # input: df: pandas data frame, variable_type: list\n",
    "    # output: df2: pandas data frame\n",
    "    df2 = df.copy()\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if variable_type[i] < 3: # binary or caterogy\n",
    "            df2[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "        else: # continuous\n",
    "            # 2020.07.14: convert str to float\n",
    "            if type(np.array(df[col])[0]) == str:\n",
    "                df[col] = pd.to_numeric(df[col],errors='coerce')\n",
    "            \n",
    "            #df2[col] = df[col].fillna(df[col].median())\n",
    "            df2[col] = df[col].fillna(df[col].mean())\n",
    "    return df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162 entries, 0 to 161\n",
      "Data columns (total 35 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   1.Gen         162 non-null    int64  \n",
      " 1   2.Sym         162 non-null    float64\n",
      " 2   3.Alc         162 non-null    int64  \n",
      " 3   4.HepB        162 non-null    float64\n",
      " 4   7.HepC        162 non-null    float64\n",
      " 5   8.Cir         162 non-null    int64  \n",
      " 6   11.Dia        162 non-null    float64\n",
      " 7   12.Obe        162 non-null    float64\n",
      " 8   14.Art        162 non-null    float64\n",
      " 9   15.CRen       162 non-null    float64\n",
      " 10  16.HIV        162 non-null    float64\n",
      " 11  19.Spl        162 non-null    float64\n",
      " 12  20.PHyp       162 non-null    float64\n",
      " 13  21.Thr        162 non-null    float64\n",
      " 14  22.LMet       162 non-null    float64\n",
      " 15  23.Rad        162 non-null    float64\n",
      " 16  24.Agedia     162 non-null    int64  \n",
      " 17  27.Sta        162 non-null    int64  \n",
      " 18  28.Encdeg     162 non-null    float64\n",
      " 19  29.Ascdeg     162 non-null    float64\n",
      " 20  30.IntNorRat  162 non-null    float64\n",
      " 21  31.Alp        162 non-null    float64\n",
      " 22  32.Hae        162 non-null    float64\n",
      " 23  33.MCorVol    162 non-null    float64\n",
      " 24  34.Leu        162 non-null    float64\n",
      " 25  35.Plat       162 non-null    float64\n",
      " 26  36.Alb        162 non-null    float64\n",
      " 27  37.Bil        162 non-null    float64\n",
      " 28  38.Ala        162 non-null    float64\n",
      " 29  39.Aspa       162 non-null    int64  \n",
      " 30  40.Gam        162 non-null    float64\n",
      " 31  41.Alk        162 non-null    float64\n",
      " 32  42.Prot       162 non-null    float64\n",
      " 33  43.Crea       162 non-null    float64\n",
      " 34  44.NNod       162 non-null    float64\n",
      "dtypes: float64(29), int64(6)\n",
      "memory usage: 44.4 KB\n"
     ]
    }
   ],
   "source": [
    "dfx_imputed = impute_missing_mean(dfx,variable_type)\n",
    "dfx_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_and_category(x,variable_type):\n",
    "    \"\"\"\n",
    "    convert binary to +-1, category to one hot; remain continuous.\n",
    "    \"\"\"    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "    # create 2 initial columns\n",
    "    x_new = np.zeros((x.shape[0],2))\n",
    "\n",
    "    for i,i_type in enumerate(variable_type):\n",
    "        if i_type == 1: # binary\n",
    "            unique_value = np.unique(x[:,i])\n",
    "            x1 = np.array([-1. if value == unique_value[0] else 1. for value in x[:,i]])        \n",
    "            x_new = np.hstack((x_new,x1[:,np.newaxis]))\n",
    "\n",
    "        elif i_type == 2: # category\n",
    "            x1 = onehot_encoder.fit_transform(x[:,i].reshape(-1,1))\n",
    "            x_new = np.hstack((x_new,x1))\n",
    "            \n",
    "        else: # continuous      \n",
    "            x_new = np.hstack((x_new,x[:,i][:,np.newaxis]))      \n",
    "\n",
    "    # drop the 2 initial column\n",
    "    x_new = x_new[:,2:]\n",
    "    \n",
    "    return x_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 39)\n",
      "[[ 1.   -1.    1.   ...  7.1   0.7   1.  ]\n",
      " [ 1.   -1.    1.   ...  7.    2.1   5.  ]\n",
      " [ 1.    1.    1.   ...  8.1   1.11  2.  ]\n",
      " ...\n",
      " [ 1.   -1.    1.   ...  7.5   1.46  5.  ]\n",
      " [ 1.   -1.    1.   ...  8.4   0.74  5.  ]\n",
      " [ 1.    1.    1.   ...  6.6   3.95  5.  ]]\n"
     ]
    }
   ],
   "source": [
    "# convert x\n",
    "x = np.array(dfx_imputed)\n",
    "x_new = convert_binary_and_category(x,variable_type)\n",
    "\n",
    "print(x_new.shape)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([63, 99]))\n"
     ]
    }
   ],
   "source": [
    "y = np.array(dfy)\n",
    "#print(np.unique(y,return_counts=True))\n",
    "\n",
    "# convert taget to 0 and 1\n",
    "y_new = y\n",
    "#y_new = np.ones(y.shape[0])\n",
    "#y_new[y =='No'] = 0\n",
    "\n",
    "print(np.unique(y_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and y and save to a file\n",
    "xy_new = np.hstack((x_new,y_new[:,np.newaxis]))\n",
    "np.savetxt('data_processed_mean.dat',xy_new,fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values by k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_category_to_integers(df,variable_type):\n",
    "    # convert binary and categorical variables to integers\n",
    "    # input: df: pandas data frame, variable_type: list\n",
    "    # output: df2: pandas data frame\n",
    "    LE = LabelEncoder()\n",
    "    df2 = df.copy()\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if variable_type[i] < 3: # binary or category\n",
    "            df2[col] = LE.fit_transform(df[col])   \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_knn(x,variable_type,i_missed,j_missed,k_nn):\n",
    "    # impute missing values by using k-NN\n",
    "    # x: 2D numpy array\n",
    "    # variable_type: 1D list,\n",
    "    # = 1 for binary, 2 for category, 3 for numeric\n",
    "\n",
    "    i_numeric = np.argwhere(variable_type > 2).flatten()\n",
    "    i_nonnumeric = np.argwhere(variable_type <= 2).flatten()\n",
    "\n",
    "    # distance between numeric features\n",
    "    x1 = x[:,i_numeric]\n",
    "    \n",
    "    # standard scaler\n",
    "    x1 = (x1 - x1.mean(axis=0))/x1.std(axis=0)\n",
    "\n",
    "    d1 = cdist(x1,x1,metric='euclidean')\n",
    "\n",
    "    # distance between binary/category features\n",
    "    x2 = x[:, i_nonnumeric]\n",
    "    d2 = cdist(x2,x2,metric='hamming')\n",
    "\n",
    "    # total distance, d1 is non-normalized while d2 is normalized\n",
    "    d = d1 + len(i_nonnumeric)*d2 \n",
    "\n",
    "    np.fill_diagonal(d,np.nan)\n",
    "    i_nn = np.argsort(d,axis=1)[:,:k_nn]\n",
    "\n",
    "    # impute missing values with k-NN\n",
    "    x_imputed = x.copy()\n",
    "    for ii in range(len(i_missed)):\n",
    "        i,j = i_missed[ii],j_missed[ii]\n",
    "        #print(i,j)\n",
    "\n",
    "        #print('i=',i,', j=',j , ', xij=', x[i,j])\n",
    "        #print('i_nn=',i_nn[i,0:k_nn],'x_inn=',x[i_nn[i,0:k_nn],j])\n",
    "\n",
    "        if j in i_numeric:\n",
    "            x_imputed[i,j] = x[i_nn[i,0:k_nn],j].mean()\n",
    "           \n",
    "        else: # category\n",
    "            value_count = mode(x[i_nn[i,0:k_nn],j])\n",
    "\n",
    "            if value_count[1][0] > 1: # count > 1\n",
    "                x_imputed[i,j] = value_count[0][0] # most frequent\n",
    "                \n",
    "            else:\n",
    "                x_imputed[i,j] = x[i_nn[i,0],j] # closest row\n",
    "               \n",
    "    return x_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx2_imputed = binary_category_to_integers(dfx_imputed,variable_type)\n",
    "\n",
    "# position of missing values\n",
    "i_missed,j_missed = np.where(dfx.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nn_list = [2,3,4,5,6,7,8,9,10,int(round(np.sqrt(dfx2_imputed.shape[0])))]\n",
    "k_nn_name = [2,3,4,5,6,7,8,9,10,'_sqrt']\n",
    "\n",
    "for ik,k_nn in enumerate(k_nn_list):\n",
    "    x_knn = impute_missing_knn(np.array(dfx2_imputed),variable_type,\n",
    "                           i_missed,j_missed,k_nn)\n",
    "\n",
    "    # convert binary to +-1, category to onehot\n",
    "    x_knn_new = convert_binary_and_category(x_knn,variable_type)\n",
    "\n",
    "    # combine X and y and save to a file\n",
    "    xy_knn = np.hstack((x_knn_new,y_new[:,np.newaxis]))\n",
    "    np.savetxt('data_processed_knn%s.dat'%(k_nn_name[ik]),xy_knn,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
