{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>center</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>BMI</th>\n",
       "      <th>type2</th>\n",
       "      <th>duration</th>\n",
       "      <th>HTN</th>\n",
       "      <th>HLP</th>\n",
       "      <th>vascinc</th>\n",
       "      <th>...</th>\n",
       "      <th>days_dialysis</th>\n",
       "      <th>RRT</th>\n",
       "      <th>KTx</th>\n",
       "      <th>SCr_fup</th>\n",
       "      <th>days_SCr_fup</th>\n",
       "      <th>crea</th>\n",
       "      <th>SCr_diff</th>\n",
       "      <th>SCr_double</th>\n",
       "      <th>progression</th>\n",
       "      <th>days_progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M003</td>\n",
       "      <td>1</td>\n",
       "      <td>56.065753</td>\n",
       "      <td>1</td>\n",
       "      <td>26.297578</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2204.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M008</td>\n",
       "      <td>1</td>\n",
       "      <td>55.339726</td>\n",
       "      <td>1</td>\n",
       "      <td>33.208550</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M009</td>\n",
       "      <td>1</td>\n",
       "      <td>75.786301</td>\n",
       "      <td>0</td>\n",
       "      <td>27.688778</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M015</td>\n",
       "      <td>1</td>\n",
       "      <td>43.213699</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1981.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M033</td>\n",
       "      <td>1</td>\n",
       "      <td>60.060274</td>\n",
       "      <td>0</td>\n",
       "      <td>26.927438</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1558.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  center        age  sex        BMI  type2  duration  HTN  HLP  \\\n",
       "0  M003       1  56.065753    1  26.297578      1       1.0    0    0   \n",
       "1  M008       1  55.339726    1  33.208550      1       0.5    1    1   \n",
       "2  M009       1  75.786301    0  27.688778      1       6.0    1    0   \n",
       "3  M015       1  43.213699    0        NaN      1       1.0    0    0   \n",
       "4  M033       1  60.060274    0  26.927438      1       4.0    1    1   \n",
       "\n",
       "   vascinc  ...  days_dialysis  RRT  KTx  SCr_fup  days_SCr_fup  crea  \\\n",
       "0        0  ...           1545    0    0     0.84        2204.0  0.87   \n",
       "1        0  ...           1506    0    0     1.00           2.0  0.98   \n",
       "2        1  ...           1539    0    0     0.82           1.0  0.81   \n",
       "3        0  ...           2197    0    0     0.73        1981.0  0.83   \n",
       "4        1  ...           1696    0    0     0.94        1558.0  0.90   \n",
       "\n",
       "   SCr_diff  SCr_double  progression  days_progression  \n",
       "0     -0.03         0.0          0.0            2204.0  \n",
       "1      0.02         0.0          0.0               2.0  \n",
       "2      0.01         0.0          0.0               1.0  \n",
       "3     -0.10         0.0          0.0            1981.0  \n",
       "4      0.04         0.0          0.0            1558.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('renal.csv',sep= ',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249 entries, 0 to 248\n",
      "Data columns (total 42 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ID                249 non-null    object \n",
      " 1   center            249 non-null    int64  \n",
      " 2   age               249 non-null    float64\n",
      " 3   sex               249 non-null    int64  \n",
      " 4   BMI               246 non-null    float64\n",
      " 5   type2             249 non-null    int64  \n",
      " 6   duration          240 non-null    float64\n",
      " 7   HTN               249 non-null    int64  \n",
      " 8   HLP               249 non-null    int64  \n",
      " 9   vascinc           249 non-null    int64  \n",
      " 10  ACE               248 non-null    float64\n",
      " 11  ARB               248 non-null    float64\n",
      " 12  statin            248 non-null    float64\n",
      " 13  hb                240 non-null    float64\n",
      " 14  CRP               232 non-null    float64\n",
      " 15  alb               235 non-null    float64\n",
      " 16  HbA1c             238 non-null    float64\n",
      " 17  ferritin          235 non-null    float64\n",
      " 18  EPO               242 non-null    float64\n",
      " 19  chol              230 non-null    float64\n",
      " 20  LDL               228 non-null    float64\n",
      " 21  HDL               229 non-null    float64\n",
      " 22  hepcidin_ngml     249 non-null    float64\n",
      " 23  GFR               184 non-null    float64\n",
      " 24  protein           189 non-null    float64\n",
      " 25  CKDEPI            248 non-null    float64\n",
      " 26  MDRD              248 non-null    float64\n",
      " 27  GFRc              248 non-null    float64\n",
      " 28  GFRm              248 non-null    float64\n",
      " 29  death             249 non-null    int64  \n",
      " 30  days_death        249 non-null    int64  \n",
      " 31  dialysis          249 non-null    int64  \n",
      " 32  days_dialysis     249 non-null    int64  \n",
      " 33  RRT               249 non-null    int64  \n",
      " 34  KTx               249 non-null    int64  \n",
      " 35  SCr_fup           212 non-null    float64\n",
      " 36  days_SCr_fup      212 non-null    float64\n",
      " 37  crea              248 non-null    float64\n",
      " 38  SCr_diff          211 non-null    float64\n",
      " 39  SCr_double        211 non-null    float64\n",
      " 40  progression       246 non-null    float64\n",
      " 41  days_progression  246 non-null    float64\n",
      "dtypes: float64(29), int64(12), object(1)\n",
      "memory usage: 81.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'death'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace empty or errors by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty/erros by np.nan\n",
    "df = df.replace(r'^\\s+$', np.nan, regex=True)\n",
    "df = df.replace('\\t','',regex=True)\n",
    "df = df.replace(' ','',regex=True)\n",
    "df = df.replace('\\?',np.nan,regex=True)\n",
    "df = df.replace('\\<',np.nan,regex=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>BMI</th>\n",
       "      <th>type2</th>\n",
       "      <th>duration</th>\n",
       "      <th>HTN</th>\n",
       "      <th>HLP</th>\n",
       "      <th>vascinc</th>\n",
       "      <th>ACE</th>\n",
       "      <th>...</th>\n",
       "      <th>days_dialysis</th>\n",
       "      <th>RRT</th>\n",
       "      <th>KTx</th>\n",
       "      <th>SCr_fup</th>\n",
       "      <th>days_SCr_fup</th>\n",
       "      <th>crea</th>\n",
       "      <th>SCr_diff</th>\n",
       "      <th>SCr_double</th>\n",
       "      <th>progression</th>\n",
       "      <th>days_progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56.065753</td>\n",
       "      <td>1</td>\n",
       "      <td>26.297578</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2204.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55.339726</td>\n",
       "      <td>1</td>\n",
       "      <td>33.208550</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>75.786301</td>\n",
       "      <td>0</td>\n",
       "      <td>27.688778</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>43.213699</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1981.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>60.060274</td>\n",
       "      <td>0</td>\n",
       "      <td>26.927438</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1558.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   center        age  sex        BMI  type2  duration  HTN  HLP  vascinc  ACE  \\\n",
       "0       1  56.065753    1  26.297578      1       1.0    0    0        0  0.0   \n",
       "1       1  55.339726    1  33.208550      1       0.5    1    1        0  1.0   \n",
       "2       1  75.786301    0  27.688778      1       6.0    1    0        1  1.0   \n",
       "3       1  43.213699    0        NaN      1       1.0    0    0        0  NaN   \n",
       "4       1  60.060274    0  26.927438      1       4.0    1    1        1  0.0   \n",
       "\n",
       "   ...  days_dialysis  RRT  KTx  SCr_fup  days_SCr_fup  crea  SCr_diff  \\\n",
       "0  ...           1545    0    0     0.84        2204.0  0.87     -0.03   \n",
       "1  ...           1506    0    0     1.00           2.0  0.98      0.02   \n",
       "2  ...           1539    0    0     0.82           1.0  0.81      0.01   \n",
       "3  ...           2197    0    0     0.73        1981.0  0.83     -0.10   \n",
       "4  ...           1696    0    0     0.94        1558.0  0.90      0.04   \n",
       "\n",
       "   SCr_double  progression  days_progression  \n",
       "0         0.0          0.0            2204.0  \n",
       "1         0.0          0.0               2.0  \n",
       "2         0.0          0.0               1.0  \n",
       "3         0.0          0.0            1981.0  \n",
       "4         0.0          0.0            1558.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the column `ID` as it is unrelated to the dependent variable\n",
    "df = df.drop(['ID'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bad_columns(df,bad_column_threshold):\n",
    "    # find bad columns having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=0))\n",
    "    bad_col = np.array([]).astype(int)\n",
    "    for i in range(len(n_null)):\n",
    "        if n_null[i] >= bad_column_threshold:\n",
    "            bad_col = np.append(bad_col,i)\n",
    "\n",
    "    #print(bad_col)\n",
    "    print('number of bad columns:',len(bad_col))\n",
    "\n",
    "    # delete bad columns\n",
    "    df = df.drop(df.columns[bad_col],axis=1)\n",
    "    #df.info()\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad columns: 8\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249 entries, 0 to 248\n",
      "Data columns (total 33 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   center            249 non-null    int64  \n",
      " 1   age               249 non-null    float64\n",
      " 2   sex               249 non-null    int64  \n",
      " 3   BMI               246 non-null    float64\n",
      " 4   type2             249 non-null    int64  \n",
      " 5   duration          240 non-null    float64\n",
      " 6   HTN               249 non-null    int64  \n",
      " 7   HLP               249 non-null    int64  \n",
      " 8   vascinc           249 non-null    int64  \n",
      " 9   ACE               248 non-null    float64\n",
      " 10  ARB               248 non-null    float64\n",
      " 11  statin            248 non-null    float64\n",
      " 12  hb                240 non-null    float64\n",
      " 13  CRP               232 non-null    float64\n",
      " 14  alb               235 non-null    float64\n",
      " 15  HbA1c             238 non-null    float64\n",
      " 16  ferritin          235 non-null    float64\n",
      " 17  EPO               242 non-null    float64\n",
      " 18  chol              230 non-null    float64\n",
      " 19  hepcidin_ngml     249 non-null    float64\n",
      " 20  CKDEPI            248 non-null    float64\n",
      " 21  MDRD              248 non-null    float64\n",
      " 22  GFRc              248 non-null    float64\n",
      " 23  GFRm              248 non-null    float64\n",
      " 24  death             249 non-null    int64  \n",
      " 25  days_death        249 non-null    int64  \n",
      " 26  dialysis          249 non-null    int64  \n",
      " 27  days_dialysis     249 non-null    int64  \n",
      " 28  RRT               249 non-null    int64  \n",
      " 29  KTx               249 non-null    int64  \n",
      " 30  crea              248 non-null    float64\n",
      " 31  progression       246 non-null    float64\n",
      " 32  days_progression  246 non-null    float64\n",
      "dtypes: float64(21), int64(12)\n",
      "memory usage: 64.3 KB\n"
     ]
    }
   ],
   "source": [
    "df = remove_bad_columns(df,20)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows where target is missing\n",
    "def find_missing_target_rows(df,target):\n",
    "    # find rows where target is missing\n",
    "    missing_row = df[target].isnull()\n",
    "    print('Number of rows where target are missing:')\n",
    "    print(sum(missing_row))\n",
    "\n",
    "    #df = df[~missing_row]\n",
    "    missing_row_indices = np.array([t for t in range(df.shape[0]) if missing_row[t]])\n",
    "    \n",
    "    return missing_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where target are missing:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_target_rows = find_missing_target_rows(df,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find bad rows which contain too many missing values, then remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_rows(df,bad_row_threshold):   \n",
    "    # find bad rows having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=1))\n",
    "    bad_row = np.array([]).astype(int)\n",
    "    for t in range(len(n_null)):\n",
    "        if n_null[t] >= bad_row_threshold:\n",
    "            bad_row = np.append(bad_row,t)\n",
    "\n",
    "    #print(bad_row)\n",
    "    print('number of bad rows:',len(bad_row))\n",
    "\n",
    "    # delete bad rows\n",
    "    #df = df.drop(bad_row)\n",
    "    #df.info()\n",
    "    return bad_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad rows: 5\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249 entries, 0 to 248\n",
      "Data columns (total 33 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   center            249 non-null    int64  \n",
      " 1   age               249 non-null    float64\n",
      " 2   sex               249 non-null    int64  \n",
      " 3   BMI               246 non-null    float64\n",
      " 4   type2             249 non-null    int64  \n",
      " 5   duration          240 non-null    float64\n",
      " 6   HTN               249 non-null    int64  \n",
      " 7   HLP               249 non-null    int64  \n",
      " 8   vascinc           249 non-null    int64  \n",
      " 9   ACE               248 non-null    float64\n",
      " 10  ARB               248 non-null    float64\n",
      " 11  statin            248 non-null    float64\n",
      " 12  hb                240 non-null    float64\n",
      " 13  CRP               232 non-null    float64\n",
      " 14  alb               235 non-null    float64\n",
      " 15  HbA1c             238 non-null    float64\n",
      " 16  ferritin          235 non-null    float64\n",
      " 17  EPO               242 non-null    float64\n",
      " 18  chol              230 non-null    float64\n",
      " 19  hepcidin_ngml     249 non-null    float64\n",
      " 20  CKDEPI            248 non-null    float64\n",
      " 21  MDRD              248 non-null    float64\n",
      " 22  GFRc              248 non-null    float64\n",
      " 23  GFRm              248 non-null    float64\n",
      " 24  death             249 non-null    int64  \n",
      " 25  days_death        249 non-null    int64  \n",
      " 26  dialysis          249 non-null    int64  \n",
      " 27  days_dialysis     249 non-null    int64  \n",
      " 28  RRT               249 non-null    int64  \n",
      " 29  KTx               249 non-null    int64  \n",
      " 30  crea              248 non-null    float64\n",
      " 31  progression       246 non-null    float64\n",
      " 32  days_progression  246 non-null    float64\n",
      "dtypes: float64(21), int64(12)\n",
      "memory usage: 64.3 KB\n"
     ]
    }
   ],
   "source": [
    "bad_rows = find_bad_rows(df,5)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows need to delete: 5\n"
     ]
    }
   ],
   "source": [
    "del_rows = np.union1d(missing_target_rows,bad_rows)\n",
    "print('number of rows need to delete:',len(del_rows))\n",
    "\n",
    "df = df.drop(del_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.drop(target,axis=1)\n",
    "dfy = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniques of each variable:\n",
      "[  4 239   2 234   2  43   2   2   2   2   2   2  80 118 125  56 178 157\n",
      " 125 126 244 244 190  99 217   2 212   4   2 113   2 220]\n"
     ]
    }
   ],
   "source": [
    "# number of uniques of each column (excluding NaN)\n",
    "nu = np.array([len(pd.unique(dfx[col].dropna())) for col in dfx.columns])\n",
    "print('number of uniques of each variable:')\n",
    "print(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_variable_type(df,nu):\n",
    "    i_binary = [] ; i_category = [] ; i_continuous = []\n",
    "    for i in range(len(nu)):\n",
    "        if nu[i] == 2: # binary \n",
    "            i_binary.append(i)\n",
    "        elif nu[i] < 5: # !!!! NOTE: this is not always correct,\n",
    "                        # it depends on data\n",
    "            i_category.append(i)\n",
    "        else:\n",
    "            i_continuous.append(i)\n",
    "\n",
    "    print('i_binary:',i_binary)\n",
    "    print('i_category:',i_category)   \n",
    "    #i_binary, i_category, i_continuous\n",
    "    \n",
    "    variable_type  = np.ones(len(nu))  # binary\n",
    "    variable_type[i_category] = 2   # categorical\n",
    "    variable_type[i_continuous] = 3 # continuous\n",
    "\n",
    "    return variable_type #,i_binary,i_category,i_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_binary: [2, 4, 6, 7, 8, 9, 10, 11, 25, 28, 30]\n",
      "i_category: [0, 27]\n",
      "variable type: [2. 3. 1. 3. 1. 3. 1. 1. 1. 1. 1. 1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 1. 3. 2. 1. 3. 1. 3.]\n"
     ]
    }
   ],
   "source": [
    "variable_type = define_variable_type(dfx,nu)\n",
    "print('variable type:',variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing values with column mean and column mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df,variable_type):\n",
    "    # impute binary and categorical variables by the most frequency (in each column)\n",
    "    # continuous variable by median\n",
    "    # input: df: pandas data frame, variable_type: list\n",
    "    # output: df2: pandas data frame\n",
    "    df2 = df.copy()\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if variable_type[i] < 3: # binary or caterogy\n",
    "            df2[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "        else: # continuous\n",
    "            #df2[col] = df[col].fillna(df[col].median())  \n",
    "            df2[col] = df[col].fillna(df[col].mean())\n",
    "    return df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 244 entries, 0 to 248\n",
      "Data columns (total 32 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   center            244 non-null    int64  \n",
      " 1   age               244 non-null    float64\n",
      " 2   sex               244 non-null    int64  \n",
      " 3   BMI               244 non-null    float64\n",
      " 4   type2             244 non-null    int64  \n",
      " 5   duration          244 non-null    float64\n",
      " 6   HTN               244 non-null    int64  \n",
      " 7   HLP               244 non-null    int64  \n",
      " 8   vascinc           244 non-null    int64  \n",
      " 9   ACE               244 non-null    float64\n",
      " 10  ARB               244 non-null    float64\n",
      " 11  statin            244 non-null    float64\n",
      " 12  hb                244 non-null    float64\n",
      " 13  CRP               244 non-null    float64\n",
      " 14  alb               244 non-null    float64\n",
      " 15  HbA1c             244 non-null    float64\n",
      " 16  ferritin          244 non-null    float64\n",
      " 17  EPO               244 non-null    float64\n",
      " 18  chol              244 non-null    float64\n",
      " 19  hepcidin_ngml     244 non-null    float64\n",
      " 20  CKDEPI            244 non-null    float64\n",
      " 21  MDRD              244 non-null    float64\n",
      " 22  GFRc              244 non-null    float64\n",
      " 23  GFRm              244 non-null    float64\n",
      " 24  days_death        244 non-null    int64  \n",
      " 25  dialysis          244 non-null    int64  \n",
      " 26  days_dialysis     244 non-null    int64  \n",
      " 27  RRT               244 non-null    int64  \n",
      " 28  KTx               244 non-null    int64  \n",
      " 29  crea              244 non-null    float64\n",
      " 30  progression       244 non-null    float64\n",
      " 31  days_progression  244 non-null    float64\n",
      "dtypes: float64(21), int64(11)\n",
      "memory usage: 62.9 KB\n"
     ]
    }
   ],
   "source": [
    "dfx_imputed = impute_missing(dfx,variable_type)\n",
    "dfx_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_and_category(x,variable_type):\n",
    "    \"\"\"\n",
    "    convert binary to +-1, category to one hot; remain continuous.\n",
    "    \"\"\"    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "    # create 2 initial columns\n",
    "    x_new = np.zeros((x.shape[0],2))\n",
    "\n",
    "    for i,i_type in enumerate(variable_type):\n",
    "        if i_type == 1: # binary\n",
    "            unique_value = np.unique(x[:,i])\n",
    "            x1 = np.array([-1. if value == unique_value[0] else 1. for value in x[:,i]])        \n",
    "            x_new = np.hstack((x_new,x1[:,np.newaxis]))\n",
    "\n",
    "        elif i_type == 2: # category\n",
    "            x1 = onehot_encoder.fit_transform(x[:,i].reshape(-1,1))\n",
    "            x_new = np.hstack((x_new,x1))\n",
    "            \n",
    "        else: # continuous      \n",
    "            x_new = np.hstack((x_new,x[:,i][:,np.newaxis]))      \n",
    "\n",
    "    # drop the 2 initial column\n",
    "    x_new = x_new[:,2:]\n",
    "    \n",
    "    return x_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, 38)\n"
     ]
    }
   ],
   "source": [
    "# convert x\n",
    "x = np.array(dfx_imputed)\n",
    "x_new = convert_binary_and_category(x,variable_type)\n",
    "\n",
    "print(x_new.shape)\n",
    "#print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([197,  47]))\n"
     ]
    }
   ],
   "source": [
    "y = np.array(dfy)\n",
    "#print(np.unique(y,return_counts=True))\n",
    "\n",
    "# convert taget to 0 and 1\n",
    "y_new = y\n",
    "#y_new = np.ones(y.shape[0])\n",
    "#y_new[y =='No'] = 0\n",
    "\n",
    "print(np.unique(y_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and y and save to a file\n",
    "xy_new = np.hstack((x_new,y_new[:,np.newaxis]))\n",
    "np.savetxt('renal_processed.dat',xy_new,fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values by k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_category_to_integers(df,variable_type):\n",
    "    # convert binary and categorical variables to integers\n",
    "    # input: df: pandas data frame, variable_type: list\n",
    "    # output: df2: pandas data frame\n",
    "    LE = LabelEncoder()\n",
    "    df2 = df.copy()\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if variable_type[i] < 3: # binary or caterogy\n",
    "            df2[col] = LE.fit_transform(df[col])   \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_knn(x,variable_type,i_missed,j_missed,k_nn):\n",
    "    # impute missing values by using k-NN\n",
    "    # x: 2D numpy array\n",
    "    # variable_type: 1D list,\n",
    "    # = 1 for binary, 2 for category, 3 for numeric\n",
    "\n",
    "    i_numeric = np.argwhere(variable_type > 2).flatten()\n",
    "    i_nonnumeric = np.argwhere(variable_type <= 2).flatten()\n",
    "\n",
    "    # distance between numeric features\n",
    "    x1 = x[:,i_numeric]\n",
    "    \n",
    "    # standard scaler\n",
    "    x1 = (x1 - x1.mean(axis=0))/x1.std(axis=0)\n",
    "\n",
    "    d1 = cdist(x1,x1,metric='euclidean')\n",
    "\n",
    "    # distance between binary/category features\n",
    "    x2 = x[:, i_nonnumeric]\n",
    "    d2 = cdist(x2,x2,metric='hamming')\n",
    "\n",
    "    # total distance, d1 is non-normalized while d2 is normalized\n",
    "    d = d1 + len(i_nonnumeric)*d2 \n",
    "\n",
    "    np.fill_diagonal(d,np.nan)\n",
    "    i_nn = np.argsort(d,axis=1)[:,:k_nn]\n",
    "\n",
    "    # impute missing values with k-NN\n",
    "    x_imputed = x.copy()\n",
    "    for ii in range(len(i_missed)):\n",
    "        i,j = i_missed[ii],j_missed[ii]\n",
    "        #print(i,j)\n",
    "\n",
    "        #print('i=',i,', j=',j , ', xij=', x[i,j])\n",
    "        #print('i_nn=',i_nn[i,0:k_nn],'x_inn=',x[i_nn[i,0:k_nn],j])\n",
    "\n",
    "        if j in i_numeric:\n",
    "            x_imputed[i,j] = x[i_nn[i,0:k_nn],j].mean()\n",
    "           \n",
    "        else: # category\n",
    "            value_count = mode(x[i_nn[i,0:k_nn],j])\n",
    "\n",
    "            if value_count[1][0] > 1: # count > 1\n",
    "                x_imputed[i,j] = value_count[0][0] # most frequent\n",
    "                \n",
    "            else:\n",
    "                x_imputed[i,j] = x[i_nn[i,0],j] # closest row\n",
    "               \n",
    "    return x_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx2_imputed = binary_category_to_integers(dfx_imputed,variable_type)\n",
    "\n",
    "# position of missing values\n",
    "i_missed,j_missed = np.where(dfx.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_nn = 5\n",
    "x_knn = impute_missing_knn(np.array(dfx2_imputed),variable_type,\n",
    "                           i_missed,j_missed,k_nn)\n",
    "\n",
    "# convert binary to +-1, category to onehot\n",
    "x_knn_new = convert_binary_and_category(x_knn,variable_type)\n",
    "\n",
    "# combine X and y and save to a file\n",
    "xy_knn = np.hstack((x_knn_new,y_new[:,np.newaxis]))\n",
    "np.savetxt('renal_processed_knn%s.dat'%(k_nn),xy_knn,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
